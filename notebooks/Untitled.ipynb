{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87aa4980-2cea-4067-b798-59a17fa2953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e671de-608f-46c5-a6f1-38061950a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "careers_page_url = \"https://job-boards.greenhouse.io/spotter\"\n",
    "company = \"spotter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe78cc-ef2f-4d4e-b2cc-35bc419ef636",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = scraping_service.get_page_source(careers_page_url)\n",
    "links = scraping_service.fetch_all_links_from_webpage(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e328307-e464-4edc-a2cf-340afd02d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a452d-f373-4a97-ae3c-29e916639a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSE_HTML_SYSTEM_PROMPT = \"\"\"Your job is to simply return structured data as requested. You parse the full document and return all the results. Provide only the answer, with no additional text or explanation. Do not answer with I Understand or similiar\"\"\"\n",
    "PARSE_OPENINGS_LINK_PROMPT = \"\"\"\n",
    "This is a JSON list of links parsed from the html content of the {} careers page. This list contains either a list of job openings, or a link to the list of openings/roles/positions/jobs. If the list contains a list of opens or jobs or positions, return None. Otherwise, \n",
    "return the link to the open positions/roles/openings. Do not acknowledge this request, do not return JSON, simply return only either the link or None, with no additional text or explanation: \\n\\n {}\n",
    "\"\"\"\n",
    "\n",
    "link_prompt = PARSE_OPENINGS_LINK_PROMPT.format(company, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525406fd-38cd-4666-a058-b686bcaffd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "openings_link = scraping_service.create_message(\n",
    "    PARSE_HTML_SYSTEM_PROMPT,\n",
    "    link_prompt,\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "print(openings_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbc29e-a023-40c8-b084-5181e33dda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"\"\"This is a JSON list of links parsed from the html content of the Spotter careers page. This list contains either a list of job openings, or a link to the list of openings/roles/positions/jobs. If the list contains a list of opens or jobs or positions, return None. Otherwise, \n",
    "return the link to the open positions/roles/openings. Do not acknowledge this request, simply return only the link, with no additional text or explanation: \n",
    "\n",
    " [{'text': '', 'link': 'https://spotter.la/'}, {'text': 'Account Manager (New York City)New York, New York, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4450346005'}, {'text': 'Ad Operations ManagerNew York, New York, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4448782005'\n",
    "}, {'text': 'Research AnalystNewCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4463358005'}, {'text': 'Manager, Product AnalyticsCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4420424005'}, {'text': 'Product Analytics LeadCulver\n",
    " City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4365397005'}, {'text': 'Senior Data Scientist - LLMCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4282898005'}, {'text': 'AI EngineerCulver City, California, United States', 'link': 'http\n",
    "s://job-boards.greenhouse.io/spotter/jobs/4413256005'}, {'text': 'Principal Backend Engineer (Microservices)Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4399899005'}, {'text': 'Senior AI Prompt EngineerCulver City, California, United States', 'link': 'https://job-boards.gree\n",
    "nhouse.io/spotter/jobs/4417247005'}, {'text': 'Senior Backend EngineerCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4324258005'}, {'text': 'Senior Front End Engineer (React / NextJS)Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/job\n",
    "s/4448044005'}, {'text': 'Engineering Manager, Developer Productivity & DevOpsCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4432984005'}, {'text': 'Principal Data EngineerCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/434045700\n",
    "5'}, {'text': 'Senior Backend API Software EngineerCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4404606005'}, {'text': 'Senior Data Engineer Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4233120005'}, {'text': 'General Counse\n",
    "lCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4401753005'}, {'text': 'Senior Human Resources Business Partner (HRBP)Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4423509005'}, {'text': 'Director, Lifecycle MarketingCulver Cit\n",
    "y, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4415342005'}, {'text': 'Greenhouse', 'link': 'http://www.greenhouse.io/'}, {'text': 'Privacy Policy', 'link': 'http://www.greenhouse.io/privacy-policy'}]\"\"\"\n",
    "\n",
    "openings_link = scraping_service.create_message(\n",
    "    PARSE_HTML_SYSTEM_PROMPT,\n",
    "    test_prompt,\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "print(openings_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4b7e1-d324-4754-b31d-35fa8d5d7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(link_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07990c2-d764-4045-9821-b018d431a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d50668-3ce7-4b91-b676-691317c5152d",
   "metadata": {},
   "source": [
    "# Research Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d2e67-0be8-4be6-bb2c-55d188fc7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import asyncio\n",
    "\n",
    "from typing import List, Optional, AsyncGenerator, Any\n",
    "\n",
    "from app.actions.find_company_action import FindCompanyAction\n",
    "from app.actions.parse_openings_action import ParseOpeningsAction\n",
    "from app.actions.find_contacts_action import FindContactsAction\n",
    "from app import Company, Contact, JobOpening\n",
    "from app.actions.research_job_action import ResearchJobAction\n",
    "from app.services.serp_service import SerpService\n",
    "from app.services.scraping_service import ScrapingService\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb24d9-feb2-4beb-8ef4-9641835f3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def research_job_openings(self, job_ids: List[str]):\n",
    "    assert self.company, \"Company is not determined?\"\n",
    "\n",
    "    desired_job_openings = list(\n",
    "        filter(lambda job: job.id in job_ids, self.openings)\n",
    "    )\n",
    "    print(\"Desired Job Openings: \", desired_job_openings)\n",
    "\n",
    "    generators = [\n",
    "        ResearchJobAction(job_opening=job).yield_action_stream()\n",
    "        for job in desired_job_openings\n",
    "    ]\n",
    "\n",
    "    async for res in asyncio.as_completed(generators):\n",
    "        print(\"Yielding research: \", res)\n",
    "        yield res\n",
    "\n",
    "\n",
    "spotter = Company(\n",
    "    name=\"Spotter\",\n",
    "    opening_link=\"https://job-boards.greenhouse.io/spotter\",\n",
    "    careers_link=\"https://job-boards.greenhouse.io/spotter\",\n",
    ")\n",
    "\n",
    "\n",
    "openings = [\n",
    "    JobOpening(\n",
    "        id=\"0\",\n",
    "        company=spotter,\n",
    "        title=\"AI Engineer\",\n",
    "        location=\"Los Angeles, CA\",\n",
    "        link=\"https://job-boards.greenhouse.io/spotter/jobs/4413256005\",\n",
    "        related=True\n",
    "    ),\n",
    "    JobOpening(\n",
    "        id=\"1\",\n",
    "        company=spotter,\n",
    "        title=\"Senior AI Prompt Engineer\",\n",
    "        location=\"Los Angeles, CA\",\n",
    "        link=\"https://job-boards.greenhouse.io/spotter/jobs/4417247005\",\n",
    "        related=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb45009-9b8e-4734-ad4b-19e0b20494d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_job_openings(job_ids: List[str]):\n",
    "    desired_job_openings = list(\n",
    "        filter(lambda job: job.id in job_ids, openings)\n",
    "    )\n",
    "    print(\"Desired Job Openings: \", desired_job_openings)\n",
    "\n",
    "    return [\n",
    "        ResearchJobAction(job_opening=job).yield_action_stream()\n",
    "        for job in desired_job_openings\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa4d5e-f3e5-4af6-89a3-916e216d3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Consume the async generator using async for\n",
    "    async for value in research_job_openings([\"0\", \"1\"]):\n",
    "        print(f\"Received: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0e5b3-8f8b-4687-939e-0ac058623943",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    f = )\n",
    "    print(f)\n",
    "    async for value in combine_generators(*research_job_openings([\"0\", \"1\"]):\n",
    "        print(value)\n",
    "        \n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b89e80-c463-4f30-825c-d3cd52921e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import AsyncIterator\n",
    "\n",
    "async def combine_generators_as_completed(*generators: AsyncIterator) -> AsyncIterator:\n",
    "    \"\"\"\n",
    "    Combines multiple async generators into a single async iterator that yields\n",
    "    results as soon as they are available from any generator.\n",
    "\n",
    "    Args:\n",
    "        generators (AsyncIterator): A variable number of async generators.\n",
    "\n",
    "    Yields:\n",
    "        The items produced by the combined generators as they become available.\n",
    "    \"\"\"\n",
    "    # Create an initial list of tasks to pull the first item from each generator\n",
    "    tasks = [asyncio.create_task(anext(gen, None)) for gen in generators]\n",
    "\n",
    "    # Map tasks to their corresponding generators\n",
    "    generator_map = {task: gen for task, gen in zip(tasks, generators)}\n",
    "\n",
    "    # Process tasks as they complete\n",
    "    while tasks:\n",
    "        # Iterate over tasks as they complete\n",
    "        for task in asyncio.as_completed(tasks):\n",
    "            result = await task\n",
    "\n",
    "            # Yield the result if it's not None\n",
    "            if result is not None:\n",
    "                yield result\n",
    "\n",
    "            # Retrieve the generator associated with the completed task\n",
    "            gen = generator_map.pop(task)\n",
    "\n",
    "            # Schedule the next item from the generator\n",
    "            next_task = asyncio.create_task(anext(gen, None))\n",
    "\n",
    "            # If the generator is exhausted, the next_task will complete immediately with None\n",
    "            if not next_task.done():\n",
    "                tasks.append(next_task)\n",
    "                generator_map[next_task] = gen\n",
    "\n",
    "        # Clean up tasks that have completed\n",
    "        tasks = [t for t in tasks if not t.done()]\n",
    "\n",
    "\n",
    "async def combine_generators_task_group(*generators: AsyncIterator) -> AsyncIterator:\n",
    "    async with asyncio.TaskGroup() as tg:\n",
    "        nexts = [tg.create_task(anext(gen, None)) for gen in generators]\n",
    "        while not all(task.done() for task in nexts):\n",
    "            await asyncio.wait(nexts, return_when=asyncio.FIRST_COMPLETED)\n",
    "            for idx, task in enumerate(nexts):\n",
    "                if task.done():\n",
    "                    if (result := task.result()) is None:\n",
    "                        continue\n",
    "                    yield result\n",
    "                    nexts[idx] = tg.create_task(anext(generators[idx], None))\n",
    "\n",
    "async def combine_generators(*generators: AsyncIterator) -> AsyncIterator:\n",
    "    tasks = {asyncio.create_task(anext(gen, None)): gen for gen in generators}\n",
    "\n",
    "    while tasks:\n",
    "        # Wait for the first task to complete and yield the result\n",
    "        done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "        for task in done:\n",
    "            if (result := task.result()) is not None:\n",
    "                yield result\n",
    "            \n",
    "            generator = tasks.pop(task)\n",
    "\n",
    "            if result and generator:\n",
    "                next_task = asyncio.create_task(anext(generator, None))\n",
    "                print(\"Rescheduling next_task \", next_task)\n",
    "                tasks[next_task] = generator\n",
    "\n",
    "# Example usage\n",
    "async def async_gen(name: str, count: int, delay: float):\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(delay)\n",
    "        yield f\"{name}: {i}\"\n",
    "\n",
    "async def main():\n",
    "    gen1 = async_gen(\"Fast\", 3, 0.5)\n",
    "    gen2 = async_gen(\"Slow\", 2, 1.0)\n",
    "    gen3 = async_gen(\"Extra Slow\", 2, 2.0)\n",
    "    \n",
    "    async for item in combine_generators(gen2, gen3):\n",
    "        print(item)\n",
    "\n",
    "await main()\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86c55ce-4b13-49a0-87ff-a4dae6a30a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.action_planner import Agent\n",
    "from app.services.scraping_service import DummyScrapingService\n",
    "from app.services.serp_service import DummySearchService\n",
    "from app.actions.research_job_action import ResearchJobAction\n",
    "from app.stub_data import spotter, spotter_openings\n",
    "from app.utils.asyncio import combine_generators\n",
    "from datetime import datetime\n",
    "\n",
    "agent = Agent(\n",
    "    serp_service=DummySearchService(), scraping_service=DummyScrapingService()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb63c22e-6bbf-43e0-8786-1fcf89a23673",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def research_job_openings(desired_job_openings):\n",
    "    generators = [\n",
    "            ResearchJobAction(\n",
    "                job_opening=job, scraping_service=DummyScrapingService()\n",
    "            ).yield_action_stream()\n",
    "            for job in desired_job_openings\n",
    "        ]\n",
    "\n",
    "    async for res in combine_generators(*generators):\n",
    "        yield res\n",
    "        await asyncio.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb95525-5f35-4fa3-a47c-7a7788384b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-07 15:15:08] ----- RETURNING TO CLIENT -----\n",
      "[2024-09-07 15:15:08] ----- RETURNED -----\n",
      "Evaluating task lifecyle...\n",
      "Rescheduling next_task  <Task pending name='Task 0' coro=<<anext_awaitable without __name__>()>>\n",
      "[2024-09-07 15:15:08] ----- RETURNING TO CLIENT -----\n",
      "[2024-09-07 15:15:08] ----- RETURNED -----\n",
      "Evaluating task lifecyle...\n",
      "Rescheduling next_task  <Task pending name='Task 1' coro=<<anext_awaitable without __name__>()>>\n",
      "Searching for query terms for  AI Engineer (https://job-boards.greenhouse.io/spotter/jobs/4413256005) in a seperate thread...\n",
      "Searching for query terms for  Senior AI Prompt Engineer (https://job-boards.greenhouse.io/spotter/jobs/4417247005) in a seperate thread...\n",
      "[2024-09-07 15:15:11] ----- RETURNING TO CLIENT -----\n",
      "[2024-09-07 15:15:11] ----- RETURNED -----\n",
      "Evaluating task lifecyle...\n",
      "Rescheduling next_task  <Task pending name='Task 0' coro=<<anext_awaitable without __name__>()>>\n",
      "Evaluating task lifecyle...\n",
      "[2024-09-07 15:15:14] ----- RETURNING TO CLIENT -----\n",
      "[2024-09-07 15:15:14] ----- RETURNED -----\n",
      "Evaluating task lifecyle...\n",
      "Rescheduling next_task  <Task pending name='Task 1' coro=<<anext_awaitable without __name__>()>>\n",
      "Evaluating task lifecyle...\n"
     ]
    }
   ],
   "source": [
    "async for res in research_job_openings(spotter_openings):\n",
    "    # Get current time and format it\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{current_time}] ----- RETURNING TO CLIENT -----\")\n",
    "    # print(f\"[{current_time}] {res}\")\n",
    "    print(f\"[{current_time}] ----- RETURNED -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2ce6e-6b94-4fc0-9b9d-f684e10aedd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reefer)",
   "language": "python",
   "name": "reefer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

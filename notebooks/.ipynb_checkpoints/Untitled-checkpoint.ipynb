{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa4980-2cea-4067-b798-59a17fa2953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e671de-608f-46c5-a6f1-38061950a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "careers_page_url = \"https://job-boards.greenhouse.io/spotter\"\n",
    "company = \"spotter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe78cc-ef2f-4d4e-b2cc-35bc419ef636",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = scraping_service.get_page_source(careers_page_url)\n",
    "links = scraping_service.fetch_all_links_from_webpage(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e328307-e464-4edc-a2cf-340afd02d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a452d-f373-4a97-ae3c-29e916639a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSE_HTML_SYSTEM_PROMPT = \"\"\"Your job is to simply return structured data as requested. You parse the full document and return all the results. Provide only the answer, with no additional text or explanation. Do not answer with I Understand or similiar\"\"\"\n",
    "PARSE_OPENINGS_LINK_PROMPT = \"\"\"\n",
    "This is a JSON list of links parsed from the html content of the {} careers page. This list contains either a list of job openings, or a link to the list of openings/roles/positions/jobs. If the list contains a list of opens or jobs or positions, return None. Otherwise, \n",
    "return the link to the open positions/roles/openings. Do not acknowledge this request, do not return JSON, simply return only either the link or None, with no additional text or explanation: \\n\\n {}\n",
    "\"\"\"\n",
    "\n",
    "link_prompt = PARSE_OPENINGS_LINK_PROMPT.format(company, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525406fd-38cd-4666-a058-b686bcaffd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "openings_link = scraping_service.create_message(\n",
    "    PARSE_HTML_SYSTEM_PROMPT,\n",
    "    link_prompt,\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "print(openings_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbc29e-a023-40c8-b084-5181e33dda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"\"\"This is a JSON list of links parsed from the html content of the Spotter careers page. This list contains either a list of job openings, or a link to the list of openings/roles/positions/jobs. If the list contains a list of opens or jobs or positions, return None. Otherwise, \n",
    "return the link to the open positions/roles/openings. Do not acknowledge this request, simply return only the link, with no additional text or explanation: \n",
    "\n",
    " [{'text': '', 'link': 'https://spotter.la/'}, {'text': 'Account Manager (New York City)New York, New York, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4450346005'}, {'text': 'Ad Operations ManagerNew York, New York, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4448782005'\n",
    "}, {'text': 'Research AnalystNewCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4463358005'}, {'text': 'Manager, Product AnalyticsCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4420424005'}, {'text': 'Product Analytics LeadCulver\n",
    " City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4365397005'}, {'text': 'Senior Data Scientist - LLMCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4282898005'}, {'text': 'AI EngineerCulver City, California, United States', 'link': 'http\n",
    "s://job-boards.greenhouse.io/spotter/jobs/4413256005'}, {'text': 'Principal Backend Engineer (Microservices)Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4399899005'}, {'text': 'Senior AI Prompt EngineerCulver City, California, United States', 'link': 'https://job-boards.gree\n",
    "nhouse.io/spotter/jobs/4417247005'}, {'text': 'Senior Backend EngineerCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4324258005'}, {'text': 'Senior Front End Engineer (React / NextJS)Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/job\n",
    "s/4448044005'}, {'text': 'Engineering Manager, Developer Productivity & DevOpsCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4432984005'}, {'text': 'Principal Data EngineerCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/434045700\n",
    "5'}, {'text': 'Senior Backend API Software EngineerCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4404606005'}, {'text': 'Senior Data Engineer Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4233120005'}, {'text': 'General Counse\n",
    "lCulver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4401753005'}, {'text': 'Senior Human Resources Business Partner (HRBP)Culver City, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4423509005'}, {'text': 'Director, Lifecycle MarketingCulver Cit\n",
    "y, California, United States', 'link': 'https://job-boards.greenhouse.io/spotter/jobs/4415342005'}, {'text': 'Greenhouse', 'link': 'http://www.greenhouse.io/'}, {'text': 'Privacy Policy', 'link': 'http://www.greenhouse.io/privacy-policy'}]\"\"\"\n",
    "\n",
    "openings_link = scraping_service.create_message(\n",
    "    PARSE_HTML_SYSTEM_PROMPT,\n",
    "    test_prompt,\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "print(openings_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4b7e1-d324-4754-b31d-35fa8d5d7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(link_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07990c2-d764-4045-9821-b018d431a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d50668-3ce7-4b91-b676-691317c5152d",
   "metadata": {},
   "source": [
    "# Research Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d2e67-0be8-4be6-bb2c-55d188fc7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import asyncio\n",
    "\n",
    "from typing import List, Optional, AsyncGenerator, Any\n",
    "\n",
    "from app.actions.find_company_action import FindCompanyAction\n",
    "from app.actions.parse_openings_action import ParseOpeningsAction\n",
    "from app.actions.find_contacts_action import FindContactsAction\n",
    "from app import Company, Contact, JobOpening\n",
    "from app.actions.research_job_action import ResearchJobAction\n",
    "from app.services.serp_service import SerpService\n",
    "from app.services.scraping_service import ScrapingService\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb24d9-feb2-4beb-8ef4-9641835f3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def research_job_openings(self, job_ids: List[str]):\n",
    "    assert self.company, \"Company is not determined?\"\n",
    "\n",
    "    desired_job_openings = list(\n",
    "        filter(lambda job: job.id in job_ids, self.openings)\n",
    "    )\n",
    "    print(\"Desired Job Openings: \", desired_job_openings)\n",
    "\n",
    "    generators = [\n",
    "        ResearchJobAction(job_opening=job).yield_action_stream()\n",
    "        for job in desired_job_openings\n",
    "    ]\n",
    "\n",
    "    async for res in asyncio.as_completed(generators):\n",
    "        print(\"Yielding research: \", res)\n",
    "        yield res\n",
    "\n",
    "\n",
    "spotter = Company(\n",
    "    name=\"Spotter\",\n",
    "    opening_link=\"https://job-boards.greenhouse.io/spotter\",\n",
    "    careers_link=\"https://job-boards.greenhouse.io/spotter\",\n",
    ")\n",
    "\n",
    "\n",
    "openings = [\n",
    "    JobOpening(\n",
    "        id=\"0\",\n",
    "        company=spotter,\n",
    "        title=\"AI Engineer\",\n",
    "        location=\"Los Angeles, CA\",\n",
    "        link=\"https://job-boards.greenhouse.io/spotter/jobs/4413256005\",\n",
    "        related=True\n",
    "    ),\n",
    "    JobOpening(\n",
    "        id=\"1\",\n",
    "        company=spotter,\n",
    "        title=\"Senior AI Prompt Engineer\",\n",
    "        location=\"Los Angeles, CA\",\n",
    "        link=\"https://job-boards.greenhouse.io/spotter/jobs/4417247005\",\n",
    "        related=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb45009-9b8e-4734-ad4b-19e0b20494d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def research_job_openings(job_ids: List[str]):\n",
    "    desired_job_openings = list(\n",
    "        filter(lambda job: job.id in job_ids, openings)\n",
    "    )\n",
    "    print(\"Desired Job Openings: \", desired_job_openings)\n",
    "\n",
    "    generators = [\n",
    "        ResearchJobAction(job_opening=job).yield_action_stream()\n",
    "        for job in desired_job_openings\n",
    "    ]\n",
    "\n",
    "    print(\"RIGHT HERE\")\n",
    "    async for res in asyncio.as_completed(generators):\n",
    "        print(\"Yielding research: \", res)\n",
    "        yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa4d5e-f3e5-4af6-89a3-916e216d3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Consume the async generator using async for\n",
    "    async for value in research_job_openings([\"0\", \"1\"]):\n",
    "        print(f\"Received: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0e5b3-8f8b-4687-939e-0ac058623943",
   "metadata": {},
   "outputs": [],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f8999-be92-4edd-b22f-ab0fc6c1bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_gen = combine_generators([async_gen_1(), async_gen_2()])\n",
    "async for result in combined_gen:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9663bc9f-277a-45b0-a387-703eea930dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def consume_generator(generator: AsyncGenerator[Any, None]) -> AsyncGenerator[Any, None]:\n",
    "    \"\"\"\n",
    "    Consumes an asynchronous generator and yields each item.\n",
    "\n",
    "    Args:\n",
    "        generator (AsyncGenerator): An asynchronous generator to consume.\n",
    "\n",
    "    Yields:\n",
    "        Any: The items produced by the generator.\n",
    "    \"\"\"\n",
    "    async for item in generator:\n",
    "        yield item\n",
    "\n",
    "async def combine_generators(generators: List[AsyncGenerator[Any, None]]) -> AsyncGenerator[Any, None]:\n",
    "    \"\"\"\n",
    "    Combines multiple asynchronous generators into a single generator that yields results as they become available.\n",
    "\n",
    "    Args:\n",
    "        generators (List[AsyncGenerator]): A list of asynchronous generators.\n",
    "\n",
    "    Yields:\n",
    "        Any: The results yielded by the combined generators, in the order they complete.\n",
    "    \"\"\"\n",
    "    # Create tasks for each generator consumption\n",
    "    tasks = [consume_generator(gen) for gen in generators]\n",
    "    \n",
    "    # Wrap each task in asyncio.create_task\n",
    "    tasks = [asyncio.create_task(gen) for gen in tasks]\n",
    "\n",
    "    # Use as_completed to yield results as tasks finish\n",
    "    for coro in asyncio.as_completed(tasks):\n",
    "        # Await each coroutine to get the result generator\n",
    "        result_gen = await coro\n",
    "        async for result in result_gen:\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a18fa7a-bac3-4780-a800-aa65335f0b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen2: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'get_coro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m combined:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(item)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[0;32mIn[44], line 33\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     32\u001b[0m     combined \u001b[38;5;241m=\u001b[39m combine_async_generators(async_gen1(), async_gen2())\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m combined:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(item)\n",
      "Cell \u001b[0;32mIn[44], line 15\u001b[0m, in \u001b[0;36mcombine_async_generators\u001b[0;34m(*generators)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m result\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Create a new task for the generator that just yielded\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     tasks\u001b[38;5;241m.\u001b[39madd(asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[43mnext_completed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coro\u001b[49m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Remove the task if the generator is exhausted\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mremove(next_completed)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'get_coro'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def combine_async_generators(*generators):\n",
    "    # Create a set of tasks from the generators\n",
    "    tasks = {asyncio.create_task(gen.__anext__()) for gen in generators}\n",
    "    \n",
    "    while tasks:\n",
    "        # Use as_completed to get results as they become available\n",
    "        for next_completed in asyncio.as_completed(tasks):\n",
    "            try:\n",
    "                result = await next_completed\n",
    "                yield result\n",
    "                \n",
    "                # Create a new task for the generator that just yielded\n",
    "                tasks.add(asyncio.create_task(next_completed.get_coro().__anext__()))\n",
    "            except StopAsyncIteration:\n",
    "                # Remove the task if the generator is exhausted\n",
    "                tasks.remove(next_completed)\n",
    "\n",
    "# Example usage\n",
    "async def async_gen1():\n",
    "    for i in range(3):\n",
    "        await asyncio.sleep(0.5)\n",
    "        yield f\"Gen1: {i}\"\n",
    "\n",
    "async def async_gen2():\n",
    "    for i in range(3):\n",
    "        await asyncio.sleep(0.3)\n",
    "        yield f\"Gen2: {i}\"\n",
    "\n",
    "async def main():\n",
    "    combined = combine_async_generators(async_gen1(), async_gen2())\n",
    "    async for item in combined:\n",
    "        print(item)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f41b2222-6c58-44fc-acea-d3d8543c1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_gen(label: str):\n",
    "    for i in range(3):\n",
    "        await asyncio.sleep(2)\n",
    "        yield f\"Gen{label}: {i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff84834e-5492-44f9-bb94-8cc3f3f927fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen1: 2\n"
     ]
    },
    {
     "ename": "StopAsyncIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopAsyncIteration\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m res_2 \u001b[38;5;241m=\u001b[39m async_gen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m results\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m())\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m results\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m())\n",
      "\u001b[0;31mStopAsyncIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_1 = async_gen('1')\n",
    "res_2 = async_gen('2')\n",
    "\n",
    "\n",
    "print(await result1.__anext__())\n",
    "print(await result2.__anext__())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "195c11f6-7e91-4da8-b064-6323e4ca81b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed732dee-df90-4618-b75d-42b8be10fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.8\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6b89e80-c463-4f30-825c-d3cd52921e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a coroutine was expected, got 'Slow: 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m combine_generators(gen2, gen3):\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28mprint\u001b[39m(item)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[0;32mIn[80], line 86\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m gen2 \u001b[38;5;241m=\u001b[39m async_gen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSlow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     84\u001b[0m gen3 \u001b[38;5;241m=\u001b[39m async_gen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Slow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2.0\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m combine_generators(gen2, gen3):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n",
      "Cell \u001b[0;32mIn[80], line 59\u001b[0m, in \u001b[0;36mcombine_generators\u001b[0;34m(*generators)\u001b[0m\n\u001b[1;32m     57\u001b[0m generator \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mpop(task)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (next_item \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m anext(generator, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     next_task \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_item\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     tasks[next_task] \u001b[38;5;241m=\u001b[39m generator\n",
      "File \u001b[0;32m~/Development/projects/reefer/.pixi/envs/default/lib/python3.12/asyncio/tasks.py:420\u001b[0m, in \u001b[0;36mcreate_task\u001b[0;34m(coro, name, context)\u001b[0m\n\u001b[1;32m    417\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# Use legacy API if context is not needed\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m     task \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n",
      "File \u001b[0;32m~/Development/projects/reefer/.pixi/envs/default/lib/python3.12/asyncio/base_events.py:458\u001b[0m, in \u001b[0;36mBaseEventLoop.create_task\u001b[0;34m(self, coro, name, context)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39m_source_traceback:\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m task\u001b[38;5;241m.\u001b[39m_source_traceback[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: a coroutine was expected, got 'Slow: 1'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import AsyncIterator\n",
    "\n",
    "async def combine_generators_as_completed(*generators: AsyncIterator) -> AsyncIterator:\n",
    "    \"\"\"\n",
    "    Combines multiple async generators into a single async iterator that yields\n",
    "    results as soon as they are available from any generator.\n",
    "\n",
    "    Args:\n",
    "        generators (AsyncIterator): A variable number of async generators.\n",
    "\n",
    "    Yields:\n",
    "        The items produced by the combined generators as they become available.\n",
    "    \"\"\"\n",
    "    # Create an initial list of tasks to pull the first item from each generator\n",
    "    tasks = [asyncio.create_task(anext(gen, None)) for gen in generators]\n",
    "\n",
    "    # Map tasks to their corresponding generators\n",
    "    generator_map = {task: gen for task, gen in zip(tasks, generators)}\n",
    "\n",
    "    # Process tasks as they complete\n",
    "    while tasks:\n",
    "        # Iterate over tasks as they complete\n",
    "        for task in asyncio.as_completed(tasks):\n",
    "            result = await task\n",
    "\n",
    "            # Yield the result if it's not None\n",
    "            if result is not None:\n",
    "                yield result\n",
    "\n",
    "            # Retrieve the generator associated with the completed task\n",
    "            gen = generator_map.pop(task)\n",
    "\n",
    "            # Schedule the next item from the generator\n",
    "            next_task = asyncio.create_task(anext(gen, None))\n",
    "\n",
    "            # If the generator is exhausted, the next_task will complete immediately with None\n",
    "            if not next_task.done():\n",
    "                tasks.append(next_task)\n",
    "                generator_map[next_task] = gen\n",
    "\n",
    "        # Clean up tasks that have completed\n",
    "        tasks = [t for t in tasks if not t.done()]\n",
    "\n",
    "async def combine_generators(*generators: AsyncIterator) -> AsyncIterator:\n",
    "    tasks = {asyncio.create_task(anext(gen, None)): gen for gen in generators}\n",
    "\n",
    "    while tasks:\n",
    "        # Wait for the first task to complete and yield the result\n",
    "        done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "        for task in done:\n",
    "            \n",
    "            if (result := task.result()) is not None:\n",
    "                yield result\n",
    "\n",
    "            # Schedule the next item from the generator, or stop if the generator is exhausted\n",
    "            generator = tasks.pop(task)\n",
    "            # if (next_item := await anext(generator, None)) is not None:\n",
    "            #     next_task = asyncio.create_task(asyncio.sleep(0, next_item))\n",
    "            #     tasks[next_task] = generator\n",
    "\n",
    "            # Schedule the next item from the generator, or stop if the generator is exhausted\n",
    "            try:\n",
    "                # Properly schedule the next item using anext\n",
    "                next_task = asyncio.create_task(anext(generator, None))\n",
    "                tasks[next_task] = generator\n",
    "            except StopAsyncIteration:\n",
    "                # If the generator is exhausted, do not add a new task\n",
    "                continue\n",
    "\n",
    "\n",
    "async def combine_generators_task_group(*generators: AsyncIterator) -> AsyncIterator:\n",
    "    async with asyncio.TaskGroup() as tg:\n",
    "        nexts = [tg.create_task(anext(gen, None)) for gen in generators]\n",
    "        while not all(task.done() for task in nexts):\n",
    "            await asyncio.wait(nexts, return_when=asyncio.FIRST_COMPLETED)\n",
    "            for idx, task in enumerate(nexts):\n",
    "                if task.done():\n",
    "                    if (result := task.result()) is None:\n",
    "                        continue\n",
    "                    yield result\n",
    "                    nexts[idx] = tg.create_task(anext(generators[idx], None))\n",
    "\n",
    "# Example usage\n",
    "async def async_gen(name: str, count: int, delay: float):\n",
    "    for i in range(count):\n",
    "        await asyncio.sleep(delay)\n",
    "        yield f\"{name}: {i}\"\n",
    "\n",
    "async def main():\n",
    "    gen1 = async_gen(\"Fast\", 3, 0.5)\n",
    "    gen2 = async_gen(\"Slow\", 2, 1.0)\n",
    "    gen3 = async_gen(\"Extra Slow\", 2, 2.0)\n",
    "    \n",
    "    async for item in combine_generators(gen2, gen3):\n",
    "        print(item)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c55ce-4b13-49a0-87ff-a4dae6a30a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reefer)",
   "language": "python",
   "name": "reefer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

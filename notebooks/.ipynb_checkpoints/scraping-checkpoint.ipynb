{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcc4de-b9d2-47e5-ab66-9c27e8045f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import json\n",
    "\n",
    "from typing import List, Set\n",
    "from anthropic import Anthropic\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b6d91-d8d1-4f44-b262-a6d88c29eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class JobOpening:\n",
    "    id: str\n",
    "    title: str\n",
    "    location: Optional[str]\n",
    "    link: str\n",
    "    related: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2dba1-29f0-487b-945f-98f25a3fd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSE_HTML_SYSTEM_PROMPT = \"\"\"Your job is to parse html and return structured data as requested. You parse the full document and return all the results. Provide only the answer, with no additional text or explanation.\"\"\"\n",
    "PARSE_OPENINGS_LINK_PROMPT = \"\"\"\n",
    "This is the html content of the {} careers page. This html is either contains a list of job openings, or a link to the list of openings/roles/positions/jobs. Return the link to the page containing openings/roles/positions/jobs. If the current page contains the list then simply return the current link.\n",
    "Dp not acknowledge this request, simply return only the link, with no additional text or explanation.\n",
    "\"\"\"\n",
    "PARSE_OPENINGS_PROMPT = \"\"\"\n",
    "This is the html content of the {} careers page containing a list of list of openings/roles/positions/jobs, each with a link. Parse the page and return a list of openings with the title of the opening, the link to the specific job page, and the location (if available). Also return a boolean field called related.\n",
    "Related should return 'True' if the the specific job is related to the criteria {} and 'False' if unrelated. Return the results as a list of json with the keys \"title\", \"link\", \"location\", and \"related\".\n",
    "Provide only the JSON, with no additional text or explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2aa33a-fadc-4502-bb77-3058a0e9359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERPDOG_API_KEY = os.getenv('SERPDOG_API_KEY')\n",
    "ANTHROPIC_API_KEY = os.getenv('CLAUDE_API_KEY')\n",
    "PROSPECT_API_KEY = os.getenv('PROSPECT_API_KEY')\n",
    "print(PROSPECT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e3df8-2d93-4db2-beae-1fce92f940b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'api_key': SERPDOG_API_KEY, 'q':'anduril careers' , 'gl':'us'}\n",
    "resp = requests.get('https://api.serpdog.io/search', params=payload)\n",
    "print (resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05292c9e-4455-4bef-8cee-1db5ff766895",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.loads(resp.text)['organic_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fadf43-5e6d-4eaf-9ff3-86f011389b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e6724-fba1-46a4-b17b-f4935bd199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run headless Chrome\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = uc.Chrome(options=chrome_options)\n",
    "driver.get('https://www.anduril.com/careers/')\n",
    "\n",
    "# Wait for the page to load completely (this can be adjusted as needed)\n",
    "driver.implicitly_wait(2)\n",
    "\n",
    "# Extract text content from the body or specific elements\n",
    "# content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "\n",
    "def get_page_source(url):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run headless Chrome\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = uc.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for JavaScript to finish loading\n",
    "    print(\"Waiting for javascript to finish loading\")\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "    \n",
    "    # Wait for the page to load completely (this can be adjusted as needed)\n",
    "    driver.implicitly_wait(2)\n",
    "    \n",
    "    # Extract text content from the body or specific elements\n",
    "    # content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "\n",
    "    return driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ab1bc-a225-4a4b-a5c7-98a8e960fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4da1c-3236-46b7-a73c-aa0b4b467920",
   "metadata": {},
   "source": [
    "# LLM Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc535a6a-d314-4fc3-b4f5-fef1a1ee143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(soup):\n",
    "    for tag in soup([\"script\", \"style\", \"iframe\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Iterate over all elements in the soup\n",
    "    for tag in soup.find_all(True):\n",
    "        # Remove the class attribute from each tag\n",
    "        tag.attrs.pop(\"class\", None)\n",
    "\n",
    "    # List of attributes to preserve\n",
    "    preserve_attrs = [\"id\", \"href\", \"datetime\"]\n",
    "\n",
    "    # Iterate over all elements in the soup\n",
    "    for tag in soup.find_all(True):\n",
    "        # Get the attributes of the current tag\n",
    "        attrs = tag.attrs.copy()  # Copy to avoid modifying while iterating\n",
    "\n",
    "        # Remove all attributes except the ones in preserve_attrs\n",
    "        for attr in attrs:\n",
    "            if attr not in preserve_attrs:\n",
    "                tag.attrs.pop(attr, None)\n",
    "\n",
    "    # Remove all comments\n",
    "    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    return soup\n",
    "\n",
    "def fetch_all_links_from_webpage(self, soup):\n",
    "    # Return the href attribute from each <a> tag\n",
    "    links = soup.find_all(\"a\")\n",
    "    return set([link.get(\"href\") for link in links if link.get(\"href\")])\n",
    "\n",
    "def resolve_url(base_url, link):\n",
    "    # Parse the link\n",
    "    parsed_link = urlparse(link)\n",
    "    \n",
    "    # Check if the link is relative (it doesn't have a scheme or netloc)\n",
    "    if not parsed_link.scheme and not parsed_link.netloc:\n",
    "        # Combine it with the base URL\n",
    "        combined_url = urljoin(base_url, link)\n",
    "        return combined_url\n",
    "    else:\n",
    "        # The link is absolute\n",
    "        return link\n",
    "\n",
    "\n",
    "class LLMService:\n",
    "    def __init__(self, anthropic_api_key: str):\n",
    "        self.client = Anthropic(api_key=anthropic_api_key)\n",
    "\n",
    "    def create_message(self, prompt, system_prompt, model, temperature, max_tokens):\n",
    "        message = self.client.messages.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            system=system_prompt,\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}],\n",
    "        )\n",
    "        return message.content[0].text\n",
    "\n",
    "    def parse_openings_from_html(self, company: str, job_type: str, raw_html: str) -> List[JobOpening]:\n",
    "        prompt = f\"{raw_html}\\n\\n {PARSE_OPENINGS_PROMPT}\".format(company, job_type)\n",
    "        text_responses = self.create_message(\n",
    "            PARSE_HTML_SYSTEM_PROMPT,\n",
    "            prompt,\n",
    "            model=\"claude-3-5-sonnet-20240620\",\n",
    "            temperature=0.1,\n",
    "            max_tokens=4096,\n",
    "        )\n",
    "        print(text_responses)\n",
    "        json_response = json.loads(text_responses)\n",
    "        print(json_response)\n",
    "        return [\n",
    "            JobOpening(id=str(idx), **json_object)\n",
    "            for idx, json_object in enumerate(json_response)\n",
    "        ]\n",
    "\n",
    "    def parse_openings_page_link_from_html(self, company: str, raw_html: str) -> Optional[str]:\n",
    "        prompt = f\"{raw_html}\\n\\n {PARSE_OPENINGS_LINK_PROMPT}\".format(company)\n",
    "        return self.create_message(\n",
    "            PARSE_HTML_SYSTEM_PROMPT,\n",
    "            prompt,\n",
    "            model=\"claude-3-5-sonnet-20240620\",\n",
    "            temperature=0.1,\n",
    "            max_tokens=4096,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95c20e-bdde-4381-b2f1-6f9df8a7c664",
   "metadata": {},
   "source": [
    "# Find Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323df03-da03-4d16-b6d7-2b01c44b15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560c0ae-fe39-4c4a-b483-c2b373cc5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_html = str(strip_html(soup))\n",
    "print(len(cleaned_html))\n",
    "\n",
    "openings_link = llm_service.parse_openings_page_link_from_html(\"anduril\", cleaned_html)\n",
    "openings_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa354777-2ee6-4efd-8318-a6631d9557a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_url = resolve_url(\"https://www.anduril.com/careers/\", openings_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546637bc-e158-4f25-9dca-65c46a373e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_service = LLMService(ANTHROPIC_API_KEY)\n",
    "page_source = get_page_source(full_url)\n",
    "soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "cleaned_html = str(strip_html(soup))\n",
    "job_openings = llm_service.parse_openings_from_html(\"anduril\", \"software engineer\", cleaned_html)\n",
    "job_openings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ca66a-015d-4fa0-b4b1-d0d21dbe7b03",
   "metadata": {},
   "source": [
    "# Find People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9cb8e-9a87-41cd-a7b7-a858431af610",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://linkedin.com/in/'\n",
    "company = \"anduril\"\n",
    "position = \"software engineering manager\"\n",
    "query = f\"site:{base_url} {company} {position}\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24936f29-cf3c-4f91-96da-cf1448f71b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'api_key': SERPDOG_API_KEY, 'q': query , 'gl':'us'}\n",
    "resp = requests.get('https://api.serpdog.io/search', params=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066c5b4-bd84-43b7-a772-c395bf546e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8847683-4f0e-487a-911c-3b687c940643",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(res['title'], res['link']) for res in json.loads(resp.text)['organic_results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfe0ce-a8b8-43a9-bdc2-6766744fbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [('Michael Nowak - Anduril Industries',\n",
    "  'https://www.linkedin.com/in/michael-nowak-ba332567'),\n",
    " ('Mike Glazer - Anduril Industries',\n",
    "  'https://www.linkedin.com/in/mike-glazer-5a885bb'),\n",
    " ('Julien Faro - Software Engineer - Anduril Industries',\n",
    "  'https://www.linkedin.com/in/julien-faro'),\n",
    " ('Thomas Weaver - Mission Software Engineer',\n",
    "  'https://www.linkedin.com/in/thomas-weaver-sw'),\n",
    " ('Varun Murthy - Mission Software Engineer',\n",
    "  'https://www.linkedin.com/in/varun-murthy-a9a4ba20a'),\n",
    " ('Nabil Enayet - Anduril Industries',\n",
    "  'https://www.linkedin.com/in/nabilenayet'),\n",
    " ('Spencer Fishman - Anduril Industries',\n",
    "  'https://www.linkedin.com/in/spencerfishman'),\n",
    " ('Shane Arnott - Anduril Industries',\n",
    "  'https://www.linkedin.com/in/shanearnott'),\n",
    " ('John Hottinger - Anduril Industries',\n",
    "  'https://www.linkedin.com/in/jhottinger'),\n",
    " ('Benjamin Colebrook - Software Engineer at Anduril',\n",
    "  'https://www.linkedin.com/in/benjamin-colebrook')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e9be0-4f5d-434f-a980-043a2fe0d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://api.getprospect.com/public/v1/email/find?name={}&company={}\"\n",
    "linkedin_search_url = 'https://api.getprospect.com/public/v1/insights/contact?linkedinUrl={}&apiKey={}'\n",
    "headers = {\"accept\": \"application/json\", }\n",
    "for title, link in test:\n",
    "    print(title)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c324e7e-97e8-4aee-af3c-25bd4fb6ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = test[0][1]\n",
    "response = requests.get(linkedin_search_url.format(link, PROSPECT_API_KEY))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a48d53a2-c739-4258-84d8-af45eacbf57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anduril\n",
      "554d5e43-4150-4f71-a134-7ab2a2d91308\n",
      "Michael Nowak\n"
     ]
    }
   ],
   "source": [
    "name = json.loads(response.text)['firstName'] + ' ' + json.loads(response.text)['lastName']\n",
    "url = \"https://api.getprospect.com/public/v1/email/find?name={}&company={}&apiKey={}\"\n",
    "\n",
    "print(company)\n",
    "print(PROSPECT_API_KEY)\n",
    "print(name)\n",
    "response = requests.get(url.format(name, company, PROSPECT_API_KEY), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd9dbdf8-1ff6-4c4d-9c89-d43d4d950b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d88afe1-537c-42b3-95d9-3e0eeadd8adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"email\":\"mnowak@anduril.com\",\"status\":\"accept_all\"}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139bc020-810e-42c4-8634-bc5f869d9a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reefer)",
   "language": "python",
   "name": "reefer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
